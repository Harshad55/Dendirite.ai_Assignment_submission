{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, auc, roc_auc_score, confusion_matrix\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Json file.\n",
    "# I have done some changes in the json file as per the screening test word file.\n",
    "myfile=open('algoparam.json','r')\n",
    "data=myfile.read()\n",
    "#print(type(data),'\\n',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data variable to json object.\n",
    "obj=json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_modified.csv\n"
     ]
    }
   ],
   "source": [
    "#Extracting only dataset object to get the file name.\n",
    "file_path=obj['design_state_data']['session_info']['dataset']\n",
    "print(file_path)\n",
    "nw_pd_file=pd.read_csv(obj['design_state_data']['session_info']['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) reading the target and type of the problem.\n",
    "def read_target_and_prdict_type(obj,nw_pd_file):\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "    print(\"Step 1: Reading target and prediction type...\")\n",
    "    global target_col,predic_type\n",
    "    predic_type=obj['design_state_data']['target']['prediction_type']\n",
    "    target_col=obj['design_state_data']['target']['target']\n",
    "    print('Prediction Type: ',predic_type,'\\nTarget Column: ',target_col)\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "    return predic_type,target_col\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**===========================================================================================================================================**\n",
      "Step 1: Reading target and prediction type...\n",
      "Prediction Type:  classification \n",
      "Target Column:  species\n",
      "**===========================================================================================================================================**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('classification', 'species')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure my function is working or not\n",
    "read_target_and_prdict_type(obj,nw_pd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Feature Handling and imputation based on JSON file instructions and parameter.\n",
    "def feature_handle_and_imputation(obj,nw_pd_file):\n",
    "    global pd_file\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "    print(\"Step 2: Handling features and performing imputation...\")\n",
    "    # Fetching \"feature_handling\" values from jSON file.\n",
    "    feature_one=obj['design_state_data']['feature_handling']\n",
    "\n",
    "    # Iterating the Features that want to handle.\n",
    "    for feature in feature_one:\n",
    "            print(feature)\n",
    "            logger.info(f\"Processing feature: {feature}\")\n",
    "\n",
    "            # select only feature from the json so that we can access the inside elements from that particular feature \n",
    "            select_feature=obj['design_state_data']['feature_handling'][feature]\n",
    "\n",
    "            # Fetch type of the data type of the column from Json file.\n",
    "            a1=obj['design_state_data']['feature_handling'][feature]['feature_variable_type']\n",
    "            #b1=obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_with']\n",
    "            #b1_with=obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_value']\n",
    "            \n",
    "            # if it is Numerical, impute, and feature is selected  then apply imputation technique.\n",
    "            if a1=='numerical' and select_feature['is_selected']==True and select_feature['feature_details']['missing_values'].lower()=='impute':\n",
    "                    \n",
    "                    # if Imputation technique is custom then it missing_values will get filled with custom value\n",
    "                    if obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_with']=='custom':\n",
    "                            print('Custom: fill with',obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_value'])\n",
    "                            logger.info(f\"Custom: Filling missing values in {feature} with {obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_value']}\")\n",
    "                            nw_pd_file[feature].fillna(obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_value'],inplace=True)\n",
    "                            print(feature,'\\n')\n",
    "                \n",
    "                    # if imputation technique is selected as a \"Average of mean\" then it will be filled with column_mean value \n",
    "                    elif obj['design_state_data']['feature_handling'][feature]['feature_details']['impute_with']=='Average of values':\n",
    "                            nw_pd_file[feature].fillna(nw_pd_file[feature].mean(),inplace=True)\n",
    "                            print('Average: \\n',feature,'\\n',nw_pd_file[feature].mean())\n",
    "                            logger.info(f\"Filling missing values in {feature} with the average value: {nw_pd_file[feature].mean()}\")\n",
    "\n",
    "            # if it is Textual then imputation techniques\n",
    "            if a1=='text':\n",
    "                    print('textual column',feature)\n",
    "                    logger.info(f\"Encoding textual feature: {feature}\")\n",
    "                    encoder=LabelEncoder()\n",
    "                    nw_pd_file[feature]=encoder.fit_transform(nw_pd_file[feature])\n",
    "                    print(nw_pd_file[feature])\n",
    "                    logger.debug(f\"Encoded values for {feature}: {nw_pd_file[feature].head()}\")\n",
    "    pd_file=nw_pd_file\n",
    "\n",
    "\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "\n",
    "\n",
    "    return nw_pd_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**===========================================================================================================================================**\n",
      "Step 2: Handling features and performing imputation...\n",
      "sepal_length\n",
      "Average: \n",
      " sepal_length \n",
      " 5.843333333333334\n",
      "sepal_width\n",
      "Custom: fill with 0\n",
      "sepal_width \n",
      "\n",
      "petal_length\n",
      "Average: \n",
      " petal_length \n",
      " 3.758666666666666\n",
      "petal_width\n",
      "species\n",
      "textual column species\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: species, Length: 150, dtype: int32\n",
      "**===========================================================================================================================================**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_handle_and_imputation(obj,nw_pd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) splitting the dataset into train_test_split before applying feature reduction technique to avoid data lekage problem.\n",
    "def split_dataset_train_test(pd_file,target_col):\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "    print(\"Step 3: Splitting dataset into train and test...\")\n",
    "    global nw_X_train,nw_X_test,Y_train,Y_test\n",
    "    # Setting the independent(x) and dependent(y) features.\n",
    "    x=pd_file.drop(labels=target_col,axis=1)\n",
    "    y=pd_file[target_col]\n",
    "    \n",
    "    # Fetching training ratio from the json file.\n",
    "    param_of_split=obj['design_state_data']['train']\n",
    "    nw_X_train, nw_X_test, Y_train, Y_test=train_test_split(x,y,train_size=param_of_split['train_ratio'],random_state=param_of_split['random_seed'])\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "\n",
    "    return nw_X_train,nw_X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**===========================================================================================================================================**\n",
      "Step 3: Splitting dataset into train and test...\n",
      "**===========================================================================================================================================**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     sepal_length  sepal_width  petal_length  petal_width\n",
       " 81            5.5          2.4           3.7          1.0\n",
       " 133           6.3          2.8           5.1          1.5\n",
       " 137           6.4          3.1           5.5          1.8\n",
       " 75            6.6          3.0           4.4          1.4\n",
       " 109           7.2          3.6           6.1          2.5\n",
       " ..            ...          ...           ...          ...\n",
       " 71            6.1          2.8           4.0          1.3\n",
       " 106           4.9          2.5           4.5          1.7\n",
       " 14            5.8          4.0           1.2          0.2\n",
       " 92            5.8          2.6           4.0          1.2\n",
       " 102           7.1          3.0           5.9          2.1\n",
       " \n",
       " [105 rows x 4 columns],\n",
       "      sepal_length  sepal_width  petal_length  petal_width\n",
       " 73            6.1          2.8           4.7          1.2\n",
       " 18            5.7          3.8           1.7          0.3\n",
       " 118           7.7          2.6           6.9          2.3\n",
       " 78            6.0          2.9           4.5          1.5\n",
       " 76            6.8          2.8           4.8          1.4\n",
       " 31            5.4          3.4           1.5          0.4\n",
       " 64            5.6          2.9           3.6          1.3\n",
       " 141           6.9          3.1           5.1          2.3\n",
       " 68            6.2          2.2           4.5          1.5\n",
       " 82            5.8          2.7           3.9          1.2\n",
       " 110           6.5          3.2           5.1          2.0\n",
       " 12            4.8          3.0           1.4          0.1\n",
       " 36            5.5          3.5           1.3          0.2\n",
       " 9             4.9          3.1           1.5          0.1\n",
       " 19            5.1          3.8           1.5          0.3\n",
       " 56            6.3          3.3           4.7          1.6\n",
       " 104           6.5          3.0           5.8          2.2\n",
       " 69            5.6          2.5           3.9          1.1\n",
       " 55            5.7          2.8           4.5          1.3\n",
       " 132           6.4          2.8           5.6          2.2\n",
       " 29            4.7          3.2           1.6          0.2\n",
       " 127           6.1          3.0           4.9          1.8\n",
       " 26            5.0          3.4           1.6          0.4\n",
       " 128           6.4          2.8           5.6          2.1\n",
       " 131           7.9          3.8           6.4          2.0\n",
       " 145           6.7          3.0           5.2          2.3\n",
       " 108           6.7          2.5           5.8          1.8\n",
       " 143           6.8          3.2           5.9          2.3\n",
       " 45            4.8          3.0           1.4          0.3\n",
       " 30            4.8          3.1           1.6          0.2\n",
       " 22            4.6          3.6           1.0          0.2\n",
       " 15            5.7          4.4           1.5          0.4\n",
       " 65            6.7          3.1           4.4          1.4\n",
       " 11            4.8          3.4           1.6          0.2\n",
       " 42            4.4          3.2           1.3          0.2\n",
       " 146           6.3          2.5           5.0          1.9\n",
       " 51            6.4          3.2           4.5          1.5\n",
       " 27            5.2          3.5           1.5          0.2\n",
       " 4             5.0          3.6           1.4          0.2\n",
       " 32            5.2          4.1           1.5          0.1\n",
       " 142           5.8          2.7           5.1          1.9\n",
       " 85            6.0          3.4           4.5          1.6\n",
       " 86            6.7          3.1           4.7          1.5\n",
       " 16            5.4          3.9           1.3          0.4\n",
       " 10            5.4          3.7           1.5          0.2,\n",
       " 81     1\n",
       " 133    2\n",
       " 137    2\n",
       " 75     1\n",
       " 109    2\n",
       "       ..\n",
       " 71     1\n",
       " 106    2\n",
       " 14     0\n",
       " 92     1\n",
       " 102    2\n",
       " Name: species, Length: 105, dtype: int32,\n",
       " 73     1\n",
       " 18     0\n",
       " 118    2\n",
       " 78     1\n",
       " 76     1\n",
       " 31     0\n",
       " 64     1\n",
       " 141    2\n",
       " 68     1\n",
       " 82     1\n",
       " 110    2\n",
       " 12     0\n",
       " 36     0\n",
       " 9      0\n",
       " 19     0\n",
       " 56     1\n",
       " 104    2\n",
       " 69     1\n",
       " 55     1\n",
       " 132    2\n",
       " 29     0\n",
       " 127    2\n",
       " 26     0\n",
       " 128    2\n",
       " 131    2\n",
       " 145    2\n",
       " 108    2\n",
       " 143    2\n",
       " 45     0\n",
       " 30     0\n",
       " 22     0\n",
       " 15     0\n",
       " 65     1\n",
       " 11     0\n",
       " 42     0\n",
       " 146    2\n",
       " 51     1\n",
       " 27     0\n",
       " 4      0\n",
       " 32     0\n",
       " 142    2\n",
       " 85     1\n",
       " 86     1\n",
       " 16     0\n",
       " 10     0\n",
       " Name: species, dtype: int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset_train_test(pd_file,target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Feature Reduction Technique\n",
    " \n",
    "def feature_reduction(nw_X_train,nw_X_test):\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "    print(\"Step 4: Performing feature reduction...\")\n",
    "    global X_train,X_test\n",
    "    feature_red=obj['design_state_data']['feature_reduction']\n",
    "\n",
    "    for feature_technique in feature_red:\n",
    "        #print(feature_technique)\n",
    "        if feature_technique=='No Reduction' and obj['design_state_data']['feature_reduction'][feature_technique]['is_selected']==True:\n",
    "            print('No Reduction')\n",
    "            pass\n",
    "\n",
    "        elif feature_technique=='Correlation with target'and obj['design_state_data']['feature_reduction'][feature_technique]['is_selected']==True:\n",
    "            print('Corelation with target Reduction')\n",
    "            #correaltion with entire dataset\n",
    "            target_corr=pd_file.corr()\n",
    "            # correlation of target variable with all features.\n",
    "            a=target_corr[target_col]\n",
    "            #converting the above matrix into DataFrame (df).\n",
    "            df=pd.DataFrame({'features':a.index,'score':abs(a.values)})\n",
    "            #Dropping the target column because the correlation with itself is 1.\n",
    "            df=df.drop(df[df['features']==target_col].index)\n",
    "            print(df)\n",
    "            # settig threshold as 0.8 this parameter is missing in the json file that's why for demo i am setting it as a 0.8.\n",
    "            threshold=0.8\n",
    "            #filtering features based on the threshold.\n",
    "            op=df[df['score']>threshold]\n",
    "            # as per the Json file i am keeping only \"no_of_feature\" who has high corelation parameters.  \n",
    "            if len(df['features'])>feature_red['Correlation with target']['num_of_features_to_keep']:\n",
    "                # sorthing in the Descending order \n",
    "                sort=df.sort_values('score',ascending=False)\n",
    "                #keeping no of feature based on the json paarameter. \n",
    "                imp_features=sort.head(feature_red['Correlation with target']['num_of_features_to_keep'])\n",
    "            # extracting only feature column from imp_features dataset.\n",
    "            column=imp_features['features']\n",
    "            # Making the list of column names only.\n",
    "            lst_feature=list(column)\n",
    "            print(lst_feature)\n",
    "            # as per the feature reduction i am  Going to keep only those features in the training and testing dataset.            \n",
    "            X_train =nw_X_train [lst_feature]\n",
    "            X_test = nw_X_test[lst_feature]\n",
    "            print(X_train)\n",
    "\n",
    "\n",
    "        elif feature_technique=='Tree-based'and obj['design_state_data']['feature_reduction'][feature_technique]['is_selected']==True:\n",
    "            print('Tree-Based Reduction')\n",
    "            \n",
    "\n",
    "        elif feature_technique=='Principal Component Analysis'and obj['design_state_data']['feature_reduction'][feature_technique]['is_selected']==True:\n",
    "            print('Principal Component Analysis')\n",
    "            X_train =StandardScaler().fit_transform(nw_X_train)\n",
    "            X_test =StandardScaler().fit_transform(nw_X_test)\n",
    "            pca=PCA(n_components=feature_red[feature_technique]['num_of_features_to_keep'])\n",
    "            X_train=pca.fit_transform(nw_X_train)\n",
    "            X_test=pca.transform(nw_X_test)\n",
    "            print(X_train)\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "\n",
    "    return X_train,X_test\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**===========================================================================================================================================**\n",
      "Step 4: Performing feature reduction...\n",
      "Principal Component Analysis\n",
      "[[-0.32301053 -0.59992892]\n",
      " [ 1.32605926 -0.11071167]\n",
      " [ 1.79434397  0.05895252]\n",
      " [ 0.79158304  0.38070629]\n",
      " [ 2.82465587  0.75726296]\n",
      " [ 0.25609611 -0.24129577]\n",
      " [ 3.29414131  0.5402165 ]\n",
      " [ 0.54073392 -0.31709254]\n",
      " [-2.78888112  0.45244159]\n",
      " [ 3.3931068   0.45540496]\n",
      " [ 0.1127914  -0.26589449]\n",
      " [-2.74574017  0.44819639]\n",
      " [-2.87596155  0.39522425]\n",
      " [-2.30791281  0.54578463]\n",
      " [-0.65624967 -1.17817458]\n",
      " [ 1.2678643  -0.17289955]\n",
      " [-2.46699107  0.08197364]\n",
      " [-2.62534981 -0.00905817]\n",
      " [-2.41359078  0.22009348]\n",
      " [ 0.23078273 -0.45009389]\n",
      " [-2.69743004  0.36159799]\n",
      " [ 0.21452705 -0.16000407]\n",
      " [ 3.40493465  1.14499487]\n",
      " [-2.95704566 -0.09444794]\n",
      " [ 0.52759678  0.07272129]\n",
      " [ 1.21332045 -0.75592755]\n",
      " [-2.68168509  1.21661965]\n",
      " [ 1.05293291 -0.1403348 ]\n",
      " [ 1.28851584 -0.55668133]\n",
      " [ 0.1313923  -0.46759906]\n",
      " [ 0.46633708 -0.45063102]\n",
      " [ 1.79474371  0.10690025]\n",
      " [ 0.04633729 -0.76126259]\n",
      " [-2.37327719  0.85676511]\n",
      " [-0.84509435 -0.92547294]\n",
      " [ 1.68272349 -0.19572419]\n",
      " [-2.81419449  0.24364347]\n",
      " [-2.97926909  0.21228734]\n",
      " [-0.20187543 -0.63003533]\n",
      " [ 1.44871243  0.29766884]\n",
      " [-2.78962585  0.02529344]\n",
      " [ 1.46070603 -0.53705315]\n",
      " [-2.73462846  0.29482875]\n",
      " [-2.51255626  0.30490503]\n",
      " [ 1.00384944 -0.06507516]\n",
      " [-1.0406801  -0.6674646 ]\n",
      " [ 2.32354338  0.37276859]\n",
      " [ 1.25603306 -0.39231109]\n",
      " [ 1.65546371 -0.47514757]\n",
      " [ 2.97505003  0.68557702]\n",
      " [ 0.03445224 -0.6192337 ]\n",
      " [-3.01361494 -0.44102975]\n",
      " [-3.34890809 -0.36701983]\n",
      " [ 1.16461058 -0.71727689]\n",
      " [ 2.51353161  0.56497511]\n",
      " [-2.86559458 -0.18529154]\n",
      " [-2.75325458  0.44216434]\n",
      " [-3.10506602 -0.35018616]\n",
      " [ 1.17286972 -0.28409668]\n",
      " [ 2.03858579  0.12373393]\n",
      " [-2.93330416  0.03730369]\n",
      " [ 2.05595981  0.22418329]\n",
      " [ 2.42218908 -0.03687439]\n",
      " [-3.00535579 -0.00784955]\n",
      " [ 0.86805913 -0.08364183]\n",
      " [ 0.97291332  0.1219726 ]\n",
      " [ 1.13921479 -0.1488252 ]\n",
      " [ 1.18501736  0.73032467]\n",
      " [ 1.79551704  0.11823901]\n",
      " [-2.63569157  0.6258266 ]\n",
      " [ 2.00170715  0.38179613]\n",
      " [ 0.39580352 -0.05729734]\n",
      " [ 1.65221233  0.09364028]\n",
      " [-0.43151585 -0.28470324]\n",
      " [-0.13891008 -0.66796064]\n",
      " [ 0.77660805  0.00720177]\n",
      " [-2.9906434  -0.79079526]\n",
      " [ 0.93291614  0.28031079]\n",
      " [ 0.33491741 -0.61725864]\n",
      " [-2.64086076  0.7081798 ]\n",
      " [ 0.12744661 -0.21722141]\n",
      " [ 2.82508327  0.35921356]\n",
      " [ 2.17195093  0.33079906]\n",
      " [-2.64400452  0.55408681]\n",
      " [-0.88823529 -0.92122775]\n",
      " [ 2.3144571   0.28969005]\n",
      " [ 2.28314646  0.48315905]\n",
      " [-2.78962585  0.02529344]\n",
      " [ 2.20520704  0.17776757]\n",
      " [-2.83356535 -0.0361691 ]\n",
      " [ 1.36040511  0.54260542]\n",
      " [ 2.73283364  0.38434942]\n",
      " [ 1.85453915 -0.16967477]\n",
      " [ 0.17653008 -0.29248105]\n",
      " [ 1.83748492  0.05470732]\n",
      " [ 0.68595889 -0.30642527]\n",
      " [ 0.60199362  0.20625977]\n",
      " [ 1.0727859  -0.58982431]\n",
      " [ 1.27226016 -0.26659151]\n",
      " [-2.41481766  0.52224741]\n",
      " [ 0.23981521 -0.00557492]\n",
      " [ 0.38131066 -1.16010395]\n",
      " [-2.72922189  1.31455681]\n",
      " [ 0.10447844 -0.33763428]\n",
      " [ 2.5095893   0.34517439]]\n",
      "**===========================================================================================================================================**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.32301053, -0.59992892],\n",
       "        [ 1.32605926, -0.11071167],\n",
       "        [ 1.79434397,  0.05895252],\n",
       "        [ 0.79158304,  0.38070629],\n",
       "        [ 2.82465587,  0.75726296],\n",
       "        [ 0.25609611, -0.24129577],\n",
       "        [ 3.29414131,  0.5402165 ],\n",
       "        [ 0.54073392, -0.31709254],\n",
       "        [-2.78888112,  0.45244159],\n",
       "        [ 3.3931068 ,  0.45540496],\n",
       "        [ 0.1127914 , -0.26589449],\n",
       "        [-2.74574017,  0.44819639],\n",
       "        [-2.87596155,  0.39522425],\n",
       "        [-2.30791281,  0.54578463],\n",
       "        [-0.65624967, -1.17817458],\n",
       "        [ 1.2678643 , -0.17289955],\n",
       "        [-2.46699107,  0.08197364],\n",
       "        [-2.62534981, -0.00905817],\n",
       "        [-2.41359078,  0.22009348],\n",
       "        [ 0.23078273, -0.45009389],\n",
       "        [-2.69743004,  0.36159799],\n",
       "        [ 0.21452705, -0.16000407],\n",
       "        [ 3.40493465,  1.14499487],\n",
       "        [-2.95704566, -0.09444794],\n",
       "        [ 0.52759678,  0.07272129],\n",
       "        [ 1.21332045, -0.75592755],\n",
       "        [-2.68168509,  1.21661965],\n",
       "        [ 1.05293291, -0.1403348 ],\n",
       "        [ 1.28851584, -0.55668133],\n",
       "        [ 0.1313923 , -0.46759906],\n",
       "        [ 0.46633708, -0.45063102],\n",
       "        [ 1.79474371,  0.10690025],\n",
       "        [ 0.04633729, -0.76126259],\n",
       "        [-2.37327719,  0.85676511],\n",
       "        [-0.84509435, -0.92547294],\n",
       "        [ 1.68272349, -0.19572419],\n",
       "        [-2.81419449,  0.24364347],\n",
       "        [-2.97926909,  0.21228734],\n",
       "        [-0.20187543, -0.63003533],\n",
       "        [ 1.44871243,  0.29766884],\n",
       "        [-2.78962585,  0.02529344],\n",
       "        [ 1.46070603, -0.53705315],\n",
       "        [-2.73462846,  0.29482875],\n",
       "        [-2.51255626,  0.30490503],\n",
       "        [ 1.00384944, -0.06507516],\n",
       "        [-1.0406801 , -0.6674646 ],\n",
       "        [ 2.32354338,  0.37276859],\n",
       "        [ 1.25603306, -0.39231109],\n",
       "        [ 1.65546371, -0.47514757],\n",
       "        [ 2.97505003,  0.68557702],\n",
       "        [ 0.03445224, -0.6192337 ],\n",
       "        [-3.01361494, -0.44102975],\n",
       "        [-3.34890809, -0.36701983],\n",
       "        [ 1.16461058, -0.71727689],\n",
       "        [ 2.51353161,  0.56497511],\n",
       "        [-2.86559458, -0.18529154],\n",
       "        [-2.75325458,  0.44216434],\n",
       "        [-3.10506602, -0.35018616],\n",
       "        [ 1.17286972, -0.28409668],\n",
       "        [ 2.03858579,  0.12373393],\n",
       "        [-2.93330416,  0.03730369],\n",
       "        [ 2.05595981,  0.22418329],\n",
       "        [ 2.42218908, -0.03687439],\n",
       "        [-3.00535579, -0.00784955],\n",
       "        [ 0.86805913, -0.08364183],\n",
       "        [ 0.97291332,  0.1219726 ],\n",
       "        [ 1.13921479, -0.1488252 ],\n",
       "        [ 1.18501736,  0.73032467],\n",
       "        [ 1.79551704,  0.11823901],\n",
       "        [-2.63569157,  0.6258266 ],\n",
       "        [ 2.00170715,  0.38179613],\n",
       "        [ 0.39580352, -0.05729734],\n",
       "        [ 1.65221233,  0.09364028],\n",
       "        [-0.43151585, -0.28470324],\n",
       "        [-0.13891008, -0.66796064],\n",
       "        [ 0.77660805,  0.00720177],\n",
       "        [-2.9906434 , -0.79079526],\n",
       "        [ 0.93291614,  0.28031079],\n",
       "        [ 0.33491741, -0.61725864],\n",
       "        [-2.64086076,  0.7081798 ],\n",
       "        [ 0.12744661, -0.21722141],\n",
       "        [ 2.82508327,  0.35921356],\n",
       "        [ 2.17195093,  0.33079906],\n",
       "        [-2.64400452,  0.55408681],\n",
       "        [-0.88823529, -0.92122775],\n",
       "        [ 2.3144571 ,  0.28969005],\n",
       "        [ 2.28314646,  0.48315905],\n",
       "        [-2.78962585,  0.02529344],\n",
       "        [ 2.20520704,  0.17776757],\n",
       "        [-2.83356535, -0.0361691 ],\n",
       "        [ 1.36040511,  0.54260542],\n",
       "        [ 2.73283364,  0.38434942],\n",
       "        [ 1.85453915, -0.16967477],\n",
       "        [ 0.17653008, -0.29248105],\n",
       "        [ 1.83748492,  0.05470732],\n",
       "        [ 0.68595889, -0.30642527],\n",
       "        [ 0.60199362,  0.20625977],\n",
       "        [ 1.0727859 , -0.58982431],\n",
       "        [ 1.27226016, -0.26659151],\n",
       "        [-2.41481766,  0.52224741],\n",
       "        [ 0.23981521, -0.00557492],\n",
       "        [ 0.38131066, -1.16010395],\n",
       "        [-2.72922189,  1.31455681],\n",
       "        [ 0.10447844, -0.33763428],\n",
       "        [ 2.5095893 ,  0.34517439]]),\n",
       " array([[ 0.80274857, -0.13410177],\n",
       "        [-2.29136594,  0.99633565],\n",
       "        [ 3.68288858,  0.242886  ],\n",
       "        [ 0.69547013, -0.12103001],\n",
       "        [ 1.21989916,  0.29289927],\n",
       "        [-2.51458169,  0.54135122],\n",
       "        [-0.29415366, -0.18909007],\n",
       "        [ 1.81643456,  0.42072909],\n",
       "        [ 0.81146463, -0.48459262],\n",
       "        [ 0.01302736, -0.24679068],\n",
       "        [ 1.55481872,  0.25549832],\n",
       "        [-2.90639031, -0.09266109],\n",
       "        [-2.72559599,  0.73934772],\n",
       "        [-2.78962585,  0.02529344],\n",
       "        [-2.68557359,  0.63537851],\n",
       "        [ 0.98993896,  0.31339991],\n",
       "        [ 2.23651675, -0.04588916],\n",
       "        [-0.08511098, -0.5120808 ],\n",
       "        [ 0.51856431, -0.37179768],\n",
       "        [ 2.04018626, -0.21502897],\n",
       "        [-2.74883012, -0.06733702],\n",
       "        [ 1.17563988, -0.09339471],\n",
       "        [-2.57786682,  0.25444509],\n",
       "        [ 2.00455972, -0.20475172],\n",
       "        [ 3.15155274,  1.35857533],\n",
       "        [ 1.83348879,  0.19634701],\n",
       "        [ 2.19812005, -0.22631388],\n",
       "        [ 2.45736207,  0.26634104],\n",
       "        [-2.83513723, -0.1132156 ],\n",
       "        [-2.70568918, -0.07158222],\n",
       "        [-3.32284998,  0.26892645],\n",
       "        [-2.46241165,  1.45180336],\n",
       "        [ 0.82283894,  0.51848998],\n",
       "        [-2.72351674,  0.14146111],\n",
       "        [-3.11695106, -0.20815727],\n",
       "        [ 1.40088444, -0.34503485],\n",
       "        [ 0.82643625,  0.35909028],\n",
       "        [-2.66617414,  0.49938168],\n",
       "        [-2.83202206,  0.45668679],\n",
       "        [-2.73745581,  0.93574558],\n",
       "        [ 1.28851584, -0.55668133],\n",
       "        [ 0.70138406,  0.22376494],\n",
       "        [ 1.11499115,  0.44872525],\n",
       "        [-2.71531142,  0.93608174],\n",
       "        [-2.60366234,  0.77494904]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_reduction(nw_X_train,nw_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) GridSearchcv: \n",
    "#    1) identify selected model. \n",
    "#    2) pass all the parameters in grid search function. \n",
    "#    3) fit and check the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Identify selected model \n",
    "def model_gridcv_score(pd_file,X_train,X_test,Y_train,Y_test):\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "    print(\"Step 5: Hyperparameter tuning using GridSearchCV...\")\n",
    "    # fetching all the listed algorithms listed in json file\n",
    "    algo_find=obj['design_state_data']['algorithms']\n",
    "    #Specified prediction type(Regresssion or classification) of each algorithm.\n",
    "    classification=['RandomForestClassifier','GBTClassifier','LogisticRegression','xg_boost','DecisionTreeClassifier','SVM']\n",
    "    regression=['RandomForestRegressor','GBTRegressor','LinearRegression','RidgeRegression','LassoRegression','ElasticNetRegression','DecisionTreeRegressor']\n",
    "\n",
    "    # Iterate all the algorithms \n",
    "    for algo in algo_find:\n",
    "        # Found algorithm If it is Regresion or classification and as per the pred_type it is not correct, and not listed in the regression list then code will get terminated. \n",
    "        if predic_type.lower()=='regression' and algo_find[algo]['is_selected']==True and algo not in regression or algo_find[algo]['is_selected']==True and algo not in classification and predic_type.lower()=='classification':\n",
    "            print('Check your Prediction_Type:\"',predic_type,'\".\\ncheck selected Model: ',algo,'\\n\\nThis is not a Valid selection.')\n",
    "            break\n",
    "        #Found algorithm If it is Regresion and listed in regression list then it will meet to the condition \n",
    "        elif algo_find[algo]['is_selected']==True and algo in regression and predic_type.lower()=='regression':\n",
    "            print(algo)\n",
    "            # For now testing Purpose i am considering only randomforestregression model but we can replicate this with all algorithms.\n",
    "            #selected_algorithm is RandomForestRegressor as per the JSON file.\n",
    "            if algo=='RandomForestRegressor':\n",
    "                model=RandomForestRegressor()\n",
    "                # RandomForestRegressor Model Hyperparameters which will pass to the GridSearchCV to find the best paarameters and model score.\n",
    "                grid_parameters={\n",
    "                    'n_estimators':[(algo_find[algo]['min_trees']+algo_find[algo]['max_trees'])//2],  # Average of min_trees and max_trees\n",
    "                    'max_features':[algo_find[algo]['feature_sampling_statergy']],  # Corresponds to the \"Default\" strategy\n",
    "                    'max_depth': [algo_find[algo]['max_depth']],  # max_depth\n",
    "                    'min_samples_leaf':[(algo_find[algo]['min_samples_per_leaf_min_value']+algo_find[algo]['min_samples_per_leaf_max_value'])//2]  # Average of min_samples_per_leaf_min_value and max_value\n",
    "                    #'n_jobs':None#[algo_find[algo]['parallelism']]  # Parallelism\n",
    "                }\n",
    "                \n",
    "        #Found algorithm If it is classification and listed in classification list then it will meet to the condition.\n",
    "        elif algo_find[algo]['is_selected']==True and algo in classification and predic_type.lower()=='classification':\n",
    "            print(algo)\n",
    "            # For now testing Purpose i am considering only classification model but we can replicate this with all algorithms.\n",
    "            #selected_algorithm is RandomForestRegressor as per the JSON file.\n",
    "            if algo=='RandomForestClassifier':\n",
    "                model=RandomForestClassifier()\n",
    "                # RandomForestClassifier Model Hyperparameters which will pass to the GridSearchCV to find the best paarameters and model score.\n",
    "                grid_parameters={\n",
    "                    'n_estimators':[(algo_find[algo]['min_trees']+algo_find[algo]['max_trees'])//2],\n",
    "                    'max_features':[algo_find[algo]['feature_sampling_statergy']],\n",
    "                    'max_depth':[algo_find[algo]['max_depth']],\n",
    "                    'min_samples_leaf':[(algo_find[algo]['min_samples_per_leaf_min_value']+algo_find[algo]['min_samples_per_leaf_max_value'])//2]\n",
    "                }\n",
    "                \n",
    "        \n",
    "        \n",
    "                \n",
    "                \n",
    "    print('Model:',model)\n",
    "    print('grid_parameters:',grid_parameters) \n",
    "    # Extracted Gridserachcv hyperparameters.           \n",
    "    hyperparameter_grid=obj['design_state_data']['hyperparameters']\n",
    "    # if Choosen Strategy is GridSerachCv then only code will execute the further process.\n",
    "    if hyperparameter_grid['stratergy']=='Grid Search':\n",
    "        if hyperparameter_grid['Time-based K-fold(with overlap)']['is_selected']==True and predic_type.lower()=='regression':\n",
    "            grid=GridSearchCV(model,param_grid=grid_parameters,n_jobs=hyperparameter_grid['parallelism'],cv=hyperparameter_grid['Time-based K-fold(with overlap)']['num_of_folds'])\n",
    "            grid.fit(X_train,Y_train)\n",
    "            print('Best Etimator:',grid.best_estimator_,'\\n Best Parameter:',grid.best_params_,'\\n Score:',grid.best_score_)\n",
    "        elif hyperparameter_grid['Time-based K-fold(with overlap)']['is_selected']==True and predic_type.lower()=='classification':\n",
    "            grid=GridSearchCV(model,param_grid=grid_parameters,n_jobs=hyperparameter_grid['parallelism'],cv=hyperparameter_grid['Time-based K-fold(with overlap)']['num_of_folds'])\n",
    "            grid.fit(X_train,Y_train)\n",
    "            print('Best Etimator:',grid.best_estimator_,'\\n Best Parameter:',grid.best_params_,'\\n Score:',grid.best_score_)\n",
    "            score=obj['design_state_data']['metrics']\n",
    "            if score['optomize_model_hyperparameters_for'].lower()=='auc' or score['optimize_threshold_for'].lower()==['f1score','f1-score','f_score']:\n",
    "                estimator=grid.best_estimator_\n",
    "                y_pred=estimator.predict(X_test)\n",
    "                # calculate f1-score   \n",
    "                f1score=f1_score(Y_test,y_pred,average='weighted')\n",
    "                print('F1-Score',f1score)\n",
    "                #if it's binary classification then only i will apply confusion matri otherwise auc_roc_curve\n",
    "                if len(pd_file[target_col].unique())<=2:\n",
    "                    # Cost Matrix fetching values from the json.\n",
    "                    tn, fp, fn, tp = confusion_matrix(Y_test, y_pred).ravel()\n",
    "                    total_gain = (tp * score[\"gain_for_true_positive\"] +\n",
    "                    tn * score[\"gain_for_true_negative\"] +\n",
    "                    fp * score[\"gain_for_false_positive\"] +\n",
    "                    fn * score[\"gain_for_false_negative\"])\n",
    "                    print('\\nConfusion-Matrix: ','\\nTrue_positive:',tp,'\\nTrue-Negtive:',tn,'\\nFalse-Positive:',fp,'\\nFalse-Nagative:',fn)\n",
    "                    print('\\nTotal Gain: ',total_gain)\n",
    "\n",
    "        elif hyperparameter_grid['Time-based K-fold(with overlap)']['is_selected']==False:\n",
    "            grid=GridSearchCV(model,param_grid=grid_parameters,n_jobs=hyperparameter_grid['parallelism'])\n",
    "            grid.fit(X_train,Y_train)\n",
    "            print('Best Etimator:',grid.best_estimator_,'\\n Best Parameter:',grid.best_params_,'\\n Score:',grid.best_score_)\n",
    "    print(\"**===========================================================================================================================================**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**===========================================================================================================================================**\n",
      "Step 5: Hyperparameter tuning using GridSearchCV...\n",
      "RandomForestClassifier\n",
      "Model: RandomForestClassifier()\n",
      "grid_parameters: {'n_estimators': [20], 'max_features': ['auto'], 'max_depth': [30], 'min_samples_leaf': [27]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Etimator: RandomForestClassifier(max_depth=30, max_features='auto', min_samples_leaf=27,\n",
      "                       n_estimators=20) \n",
      " Best Parameter: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 27, 'n_estimators': 20} \n",
      " Score: 0.7881263616557734\n",
      "F1-Score 0.6442706636255023\n",
      "**===========================================================================================================================================**\n"
     ]
    }
   ],
   "source": [
    "model_gridcv_score(pd_file,X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**===========================================================================================================================================**\n",
      "Step 1: Reading target and prediction type...\n",
      "Prediction Type:  classification \n",
      "Target Column:  species\n",
      "**===========================================================================================================================================**\n",
      "**===========================================================================================================================================**\n",
      "Step 2: Handling features and performing imputation...\n",
      "sepal_length\n",
      "Average: \n",
      " sepal_length \n",
      " 5.843333333333334\n",
      "sepal_width\n",
      "Custom: fill with 0\n",
      "sepal_width \n",
      "\n",
      "petal_length\n",
      "Average: \n",
      " petal_length \n",
      " 3.758666666666666\n",
      "petal_width\n",
      "species\n",
      "textual column species\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: species, Length: 150, dtype: int64\n",
      "**===========================================================================================================================================**\n",
      "**===========================================================================================================================================**\n",
      "Step 3: Splitting dataset into train and test...\n",
      "**===========================================================================================================================================**\n",
      "**===========================================================================================================================================**\n",
      "Step 4: Performing feature reduction...\n",
      "Principal Component Analysis\n",
      "[[-0.32301053 -0.59992892]\n",
      " [ 1.32605926 -0.11071167]\n",
      " [ 1.79434397  0.05895252]\n",
      " [ 0.79158304  0.38070629]\n",
      " [ 2.82465587  0.75726296]\n",
      " [ 0.25609611 -0.24129577]\n",
      " [ 3.29414131  0.5402165 ]\n",
      " [ 0.54073392 -0.31709254]\n",
      " [-2.78888112  0.45244159]\n",
      " [ 3.3931068   0.45540496]\n",
      " [ 0.1127914  -0.26589449]\n",
      " [-2.74574017  0.44819639]\n",
      " [-2.87596155  0.39522425]\n",
      " [-2.30791281  0.54578463]\n",
      " [-0.65624967 -1.17817458]\n",
      " [ 1.2678643  -0.17289955]\n",
      " [-2.46699107  0.08197364]\n",
      " [-2.62534981 -0.00905817]\n",
      " [-2.41359078  0.22009348]\n",
      " [ 0.23078273 -0.45009389]\n",
      " [-2.69743004  0.36159799]\n",
      " [ 0.21452705 -0.16000407]\n",
      " [ 3.40493465  1.14499487]\n",
      " [-2.95704566 -0.09444794]\n",
      " [ 0.52759678  0.07272129]\n",
      " [ 1.21332045 -0.75592755]\n",
      " [-2.68168509  1.21661965]\n",
      " [ 1.05293291 -0.1403348 ]\n",
      " [ 1.28851584 -0.55668133]\n",
      " [ 0.1313923  -0.46759906]\n",
      " [ 0.46633708 -0.45063102]\n",
      " [ 1.79474371  0.10690025]\n",
      " [ 0.04633729 -0.76126259]\n",
      " [-2.37327719  0.85676511]\n",
      " [-0.84509435 -0.92547294]\n",
      " [ 1.68272349 -0.19572419]\n",
      " [-2.81419449  0.24364347]\n",
      " [-2.97926909  0.21228734]\n",
      " [-0.20187543 -0.63003533]\n",
      " [ 1.44871243  0.29766884]\n",
      " [-2.78962585  0.02529344]\n",
      " [ 1.46070603 -0.53705315]\n",
      " [-2.73462846  0.29482875]\n",
      " [-2.51255626  0.30490503]\n",
      " [ 1.00384944 -0.06507516]\n",
      " [-1.0406801  -0.6674646 ]\n",
      " [ 2.32354338  0.37276859]\n",
      " [ 1.25603306 -0.39231109]\n",
      " [ 1.65546371 -0.47514757]\n",
      " [ 2.97505003  0.68557702]\n",
      " [ 0.03445224 -0.6192337 ]\n",
      " [-3.01361494 -0.44102975]\n",
      " [-3.34890809 -0.36701983]\n",
      " [ 1.16461058 -0.71727689]\n",
      " [ 2.51353161  0.56497511]\n",
      " [-2.86559458 -0.18529154]\n",
      " [-2.75325458  0.44216434]\n",
      " [-3.10506602 -0.35018616]\n",
      " [ 1.17286972 -0.28409668]\n",
      " [ 2.03858579  0.12373393]\n",
      " [-2.93330416  0.03730369]\n",
      " [ 2.05595981  0.22418329]\n",
      " [ 2.42218908 -0.03687439]\n",
      " [-3.00535579 -0.00784955]\n",
      " [ 0.86805913 -0.08364183]\n",
      " [ 0.97291332  0.1219726 ]\n",
      " [ 1.13921479 -0.1488252 ]\n",
      " [ 1.18501736  0.73032467]\n",
      " [ 1.79551704  0.11823901]\n",
      " [-2.63569157  0.6258266 ]\n",
      " [ 2.00170715  0.38179613]\n",
      " [ 0.39580352 -0.05729734]\n",
      " [ 1.65221233  0.09364028]\n",
      " [-0.43151585 -0.28470324]\n",
      " [-0.13891008 -0.66796064]\n",
      " [ 0.77660805  0.00720177]\n",
      " [-2.9906434  -0.79079526]\n",
      " [ 0.93291614  0.28031079]\n",
      " [ 0.33491741 -0.61725864]\n",
      " [-2.64086076  0.7081798 ]\n",
      " [ 0.12744661 -0.21722141]\n",
      " [ 2.82508327  0.35921356]\n",
      " [ 2.17195093  0.33079906]\n",
      " [-2.64400452  0.55408681]\n",
      " [-0.88823529 -0.92122775]\n",
      " [ 2.3144571   0.28969005]\n",
      " [ 2.28314646  0.48315905]\n",
      " [-2.78962585  0.02529344]\n",
      " [ 2.20520704  0.17776757]\n",
      " [-2.83356535 -0.0361691 ]\n",
      " [ 1.36040511  0.54260542]\n",
      " [ 2.73283364  0.38434942]\n",
      " [ 1.85453915 -0.16967477]\n",
      " [ 0.17653008 -0.29248105]\n",
      " [ 1.83748492  0.05470732]\n",
      " [ 0.68595889 -0.30642527]\n",
      " [ 0.60199362  0.20625977]\n",
      " [ 1.0727859  -0.58982431]\n",
      " [ 1.27226016 -0.26659151]\n",
      " [-2.41481766  0.52224741]\n",
      " [ 0.23981521 -0.00557492]\n",
      " [ 0.38131066 -1.16010395]\n",
      " [-2.72922189  1.31455681]\n",
      " [ 0.10447844 -0.33763428]\n",
      " [ 2.5095893   0.34517439]]\n",
      "**===========================================================================================================================================**\n",
      "**===========================================================================================================================================**\n",
      "Step 5: Hyperparameter tuning using GridSearchCV...\n",
      "RandomForestClassifier\n",
      "Model: RandomForestClassifier()\n",
      "grid_parameters: {'n_estimators': [20], 'max_features': ['auto'], 'max_depth': [30], 'min_samples_leaf': [27]}\n",
      "Best Etimator: RandomForestClassifier(max_depth=30, max_features='auto', min_samples_leaf=27,\n",
      "                       n_estimators=20) \n",
      " Best Parameter: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 27, 'n_estimators': 20} \n",
      " Score: 0.7489106753812637\n",
      "F1-Score 0.9324337831084458\n",
      "**===========================================================================================================================================**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 6) Creating Pipline to streamline the workflow.\n",
    "\n",
    "pipline=Pipeline(steps=[\n",
    "    ('Target_and_problem_type',read_target_and_prdict_type(obj,nw_pd_file)),\n",
    "    ('Feature_Handling_and_Imputation',feature_handle_and_imputation(obj,nw_pd_file)),\n",
    "    ('Splitting_of_dataset',split_dataset_train_test(pd_file,target_col)),\n",
    "    ('Feature_Reduction',feature_reduction(nw_X_train,nw_X_test)),\n",
    "    ('Hyperparameter_tunning_using_gridsearchcv',model_gridcv_score(pd_file,X_train,X_test,Y_train,Y_test))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
